{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dangbb/vlsp-final-year/blob/main/1_%2B_1_%3D_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdr3oirloFgY"
      },
      "source": [
        "# Load git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_oBbAEFD2DJK"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/vlsp-final-year\n",
        "!rm -rf /content/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scXWgdVQSq-z",
        "outputId": "00b34847-3eb0-419e-b217-ea4f926074b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repository'...\n",
            "remote: Support for password authentication was removed on August 13, 2021.\n",
            "remote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\n",
            "fatal: Authentication failed for 'https://dangbb:Tin31082011@github.com/dangbb/repository.git/'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://:$p@github.com/dangbb/repository.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljCK1hfJjvf-",
        "outputId": "5a29c44d-82c2-4ab1-abad-85393f48287d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/a/gm.uit.edu.vn/uc?id=1pXJZ9eHp6DWkQ5MhCzmWYsKyLQEDiodz\n",
            "To: /content/vn_sbert_deploy.tar.gz\n",
            "100% 485M/485M [00:02<00:00, 193MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/a/gm.uit.edu.vn/uc?id=1pXJZ9eHp6DWkQ5MhCzmWYsKyLQEDiodz&export=download\n",
        "!tar xzf /content/vn_sbert_deploy.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJhnouEDkDZo",
        "outputId": "a2aae6bf-d67c-4d08-91d0-871e87853cfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M   116MB/s    in 0.2s    \n",
            "vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.04s   \n",
            "wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.02s   \n"
          ]
        }
      ],
      "source": [
        "!mkdir -p vncorenlp/models/wordsegmenter\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
        "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Vs4pGbkj-J"
      },
      "outputs": [],
      "source": [
        "!mv /content/vn_sbert_deploy /content/vlsp-final-year/external\n",
        "!mv /content/vncorenlp /content/vlsp-final-year/external"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv58ZL-KlWw9"
      },
      "source": [
        "Get into file: \n",
        "```/content/vlsp-final-year/external/vn_sbert_deploy/bpe``` \n",
        "\n",
        "Change `bpe_path` to: `/content/vlsp-final-year/external/vn_sbert_deploy/bpe`\n",
        "\n",
        "Change `vncorenlp_path` to: `/content/vlsp-final-year/external/vncorenlp/VnCoreNLP-1.1.1.jar`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O24JN-yfn8wi"
      },
      "source": [
        "# Change env "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwJS0zmeng1d"
      },
      "source": [
        "Chỉnh sửa file env.json:\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "    \"name\": \"rerun-after-take-summary\",\n",
        "    \"train_path\": \"/content/vlsp-final-year/dataset/vlsp_2022_abmusu_train_data_new.jsonl\",\n",
        "    \"valid_path\": \"/content/vlsp-final-year/dataset/vlsp_2022_abmusu_validation_data_new.jsonl\",\n",
        "    \"models\": [\n",
        "        {\n",
        "            \"id\": 0,\n",
        "            \"source\": \"sent_splitted_token\",\n",
        "            \"name\": \"textrank\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [16, 0.2],\n",
        "            \"threshold\": [],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": 1,\n",
        "            \"source\": \"sent_splitted_text\",\n",
        "            \"name\": \"mmr\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [0.2],\n",
        "            \"net_params\": [16, 0.2],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": 2,\n",
        "            \"source\": \"sent_splitted_token\",\n",
        "            \"name\": \"lexrank\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [16, 0.2],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"\",\n",
        "                \"distance\": \"\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"\"\n",
        "            },\n",
        "            \"training_required\": true,\n",
        "            \"document_convention\": \"cluster\",\n",
        "            \"threshold\": 0.1\n",
        "        },\n",
        "        {\n",
        "            \"id\": 3,\n",
        "            \"source\": \"sent_splitted_token\",\n",
        "            \"name\": \"lexrank\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [16, 0.2],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"\",\n",
        "                \"distance\": \"\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"\"\n",
        "            },\n",
        "            \"training_required\": true,\n",
        "            \"document_convention\": \"sentence\",\n",
        "            \"threshold\": 0.1\n",
        "        },\n",
        "        {\n",
        "            \"id\": 4,\n",
        "            \"source\": \"sent_splitted_token\",\n",
        "            \"name\": \"mlp\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [16, 0.2],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": true,\n",
        "            \"document_convention\": \"cluster\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": 5,\n",
        "            \"source\": \"sent_splitted_token\",\n",
        "            \"name\": \"random\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [16, 0.2],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": 6,\n",
        "            \"source\": \"sent_splitted_token\",\n",
        "            \"name\": \"custom_mlp_oracle\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [16, 0.2],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": 7,\n",
        "            \"source\": \"sent_splitted_token\",\n",
        "            \"name\": \"textrank_mmr\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [16, 0.2],\n",
        "            \"net_params\": [8, 0.1],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": 8,\n",
        "            \"source\": \"sent_splitted_token\",\n",
        "            \"name\": \"lexrank_bert\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [8, 0.1],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\",\n",
        "            \"threshold\": 0.1\n",
        "        },\n",
        "        {\n",
        "            \"id\": 9,\n",
        "            \"source\": \"sent_splitted_text\",\n",
        "            \"name\": \"mmr_query\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [8, 0.1],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\",\n",
        "            \"threshold\": 0.1\n",
        "        },\n",
        "        {\n",
        "            \"id\": 10,\n",
        "            \"source\": \"sent_splitted_text\",\n",
        "            \"name\": \"mmr_query_best_title\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [8, 0.1],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\",\n",
        "            \"threshold\": 0.1\n",
        "        }, {\n",
        "            \"id\": 11,\n",
        "            \"source\": \"sent_splitted_text\",\n",
        "            \"name\": \"mmr_query_anchor\",\n",
        "            \"count_word\": true,\n",
        "            \"params\": [8, 0.1],\n",
        "            \"net_params\": [8, 0.1],\n",
        "            \"n_words\": 200,\n",
        "            \"sigma\": 0.7,\n",
        "            \"embedding\": {\n",
        "                \"model\": \"SBERT\",\n",
        "                \"distance\": \"cosine\",\n",
        "                \"max_df\": 0.5,\n",
        "                \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "            },\n",
        "            \"training_required\": false,\n",
        "            \"document_convention\": \"cluster\",\n",
        "            \"threshold\": 0.1\n",
        "        }\n",
        "    ],\n",
        "    \"eval\": {\n",
        "        \"name\": \"pip_rouge\"\n",
        "    },\n",
        "    \"embedding\": {\n",
        "        \"model\": \"SBERT\",\n",
        "        \"distance\": \"cosine\",\n",
        "        \"max_df\": 0.5,\n",
        "        \"bart_path\": \"/content/vlsp-final-year/external/vn_sbert_deploy/phobert_base_mean_tokens_NLI_STS\"\n",
        "    },\n",
        "    \"reset\": true,\n",
        "    \"result_path\": \"/content/vlsp-final-year/data/result\",\n",
        "    \"debug\": false,\n",
        "    \"topic_path\": \"/content/vlsp-final-year/data/term_freq\",\n",
        "    \"stopword_path\": \"/content/vlsp-final-year/data/stopword\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ3LJcoSkgTz"
      },
      "source": [
        "# Install requirement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gkN1iG7Om_Jg",
        "outputId": "4752b637-d506-4f0d-e618-7e1bb765dd8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting absl-py==1.1.0\n",
            "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Using cached antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "Collecting anyio==3.6.1\n",
            "  Using cached anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "Collecting argon2-cffi==21.3.0\n",
            "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Collecting argon2-cffi-bindings==21.2.0\n",
            "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "Collecting asttokens==2.0.5\n",
            "  Using cached asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Collecting attrs==21.4.0\n",
            "  Using cached attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 8)) (0.2.0)\n",
            "Collecting beautifulsoup4==4.11.1\n",
            "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "Collecting bitarray==2.6.0\n",
            "  Using cached bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "Requirement already satisfied: bleach==5.0.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 11)) (5.0.1)\n",
            "Collecting blis==0.4.1\n",
            "  Using cached blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
            "Collecting breadability==0.1.20\n",
            "  Using cached breadability-0.1.20.tar.gz (32 kB)\n",
            "Collecting catalogue==2.0.7\n",
            "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cffi==1.15.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 15)) (1.15.1)\n",
            "Collecting chardet==5.0.0\n",
            "  Using cached chardet-5.0.0-py3-none-any.whl (193 kB)\n",
            "Collecting charset-normalizer==2.1.0\n",
            "  Using cached charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 18)) (7.1.2)\n",
            "Collecting colorama==0.4.5\n",
            "  Using cached colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 20)) (0.11.0)\n",
            "Collecting cymem==2.0.6\n",
            "  Using cached cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
            "Requirement already satisfied: Cython==0.29.32 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 22)) (0.29.32)\n",
            "Collecting debugpy==1.6.2\n",
            "  Using cached debugpy-1.6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.8 MB)\n",
            "Collecting decorator==5.1.1\n",
            "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 25)) (0.7.1)\n",
            "Collecting docopt==0.6.2\n",
            "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 27)) (0.4)\n",
            "Collecting executing==0.8.3\n",
            "  Using cached executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting fairseq==0.12.2\n",
            "  Using cached fairseq-0.12.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
            "Collecting fastapi==0.81.0\n",
            "  Using cached fastapi-0.81.0-py3-none-any.whl (54 kB)\n",
            "Collecting fastBPE==0.1.0\n",
            "  Using cached fastBPE-0.1.0.tar.gz (35 kB)\n",
            "Collecting fastjsonschema==2.15.3\n",
            "  Using cached fastjsonschema-2.15.3-py3-none-any.whl (22 kB)\n",
            "Collecting filelock==3.7.1\n",
            "  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Collecting fonttools==4.33.3\n",
            "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
            "Collecting gdown==4.5.3\n",
            "  Using cached gdown-4.5.3.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting graphviz==0.20\n",
            "  Using cached graphviz-0.20-py3-none-any.whl (46 kB)\n",
            "Collecting h11==0.13.0\n",
            "  Using cached h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "Collecting huggingface-hub==0.8.1\n",
            "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "Collecting hydra-core==1.0.7\n",
            "  Using cached hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "Collecting icecream==2.1.2\n",
            "  Using cached icecream-2.1.2-py2.py3-none-any.whl (8.3 kB)\n",
            "Collecting idna==3.3\n",
            "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
            "Collecting importlib-metadata==4.12.0\n",
            "  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
            "Collecting importlib-resources==5.8.0\n",
            "  Using cached importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
            "Collecting ipykernel==6.15.0\n",
            "  Using cached ipykernel-6.15.0-py3-none-any.whl (133 kB)\n",
            "Collecting ipython==7.34.0\n",
            "  Using cached ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 46)) (0.2.0)\n",
            "Requirement already satisfied: ipywidgets==7.7.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 47)) (7.7.1)\n",
            "Collecting jedi==0.18.1\n",
            "  Using cached jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Collecting Jinja2==3.1.2\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting joblib==1.1.0\n",
            "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Collecting jsonschema==4.6.2\n",
            "  Using cached jsonschema-4.6.2-py3-none-any.whl (80 kB)\n",
            "Collecting jupyter==1.0.0\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting jupyter-client==7.3.4\n",
            "  Using cached jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n",
            "Collecting jupyter-console==6.4.4\n",
            "  Using cached jupyter_console-6.4.4-py3-none-any.whl (22 kB)\n",
            "Collecting jupyter-core==4.11.0\n",
            "  Using cached jupyter_core-4.11.0-py3-none-any.whl (88 kB)\n",
            "Collecting jupyterlab-pygments==0.2.2\n",
            "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting jupyterlab-widgets==1.1.1\n",
            "  Using cached jupyterlab_widgets-1.1.1-py3-none-any.whl (245 kB)\n",
            "Collecting kiwisolver==1.4.3\n",
            "  Using cached kiwisolver-1.4.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: langcodes==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 59)) (3.3.0)\n",
            "Collecting lexrank==0.1.0\n",
            "  Using cached lexrank-0.1.0-py3-none-any.whl (69 kB)\n",
            "Requirement already satisfied: lxml==4.9.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 61)) (4.9.1)\n",
            "Collecting MarkupSafe==2.1.1\n",
            "  Using cached MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting matplotlib==3.5.2\n",
            "  Using cached matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Collecting matplotlib-inline==0.1.3\n",
            "  Using cached matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 65)) (0.8.4)\n",
            "Collecting mkl-fft==1.3.1\n",
            "  Using cached mkl_fft-1.3.1-16-cp37-cp37m-manylinux2014_x86_64.whl (241 kB)\n",
            "Collecting mkl-service==2.4.0\n",
            "  Using cached mkl_service-2.4.0-11-cp37-cp37m-manylinux2014_x86_64.whl (63 kB)\n",
            "Collecting murmurhash==1.0.7\n",
            "  Using cached murmurhash-1.0.7-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Collecting nbclient==0.6.6\n",
            "  Using cached nbclient-0.6.6-py3-none-any.whl (71 kB)\n",
            "Collecting nbconvert==6.5.0\n",
            "  Using cached nbconvert-6.5.0-py3-none-any.whl (561 kB)\n",
            "Collecting nbformat==5.4.0\n",
            "  Using cached nbformat-5.4.0-py3-none-any.whl (73 kB)\n",
            "Collecting nest-asyncio==1.5.5\n",
            "  Using cached nest_asyncio-1.5.5-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: networkx==2.6.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 73)) (2.6.3)\n",
            "Requirement already satisfied: nltk==3.7 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 74)) (3.7)\n",
            "Collecting notebook==6.4.12\n",
            "  Using cached notebook-6.4.12-py3-none-any.whl (9.9 MB)\n",
            "Collecting omegaconf==2.0.6\n",
            "  Using cached omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: packaging==21.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 77)) (21.3)\n",
            "Requirement already satisfied: pandas==1.3.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 78)) (1.3.5)\n",
            "Requirement already satisfied: pandocfilters==1.5.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 79)) (1.5.0)\n",
            "Requirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 80)) (0.8.3)\n",
            "Collecting path==16.4.0\n",
            "  Using cached path-16.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting path.py==12.5.0\n",
            "  Using cached path.py-12.5.0-py3-none-any.whl (2.3 kB)\n",
            "Requirement already satisfied: pathy==0.6.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 83)) (0.6.2)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 84)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 85)) (0.7.5)\n",
            "Collecting Pillow==9.0.1\n",
            "  Using cached Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Collecting plac==1.1.3\n",
            "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Collecting platformdirs==2.5.2\n",
            "  Using cached platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting portalocker==2.5.1\n",
            "  Using cached portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting preshed==3.0.6\n",
            "  Using cached preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
            "Collecting prometheus-client==0.14.1\n",
            "  Using cached prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
            "Collecting prompt-toolkit==3.0.30\n",
            "  Using cached prompt_toolkit-3.0.30-py3-none-any.whl (381 kB)\n",
            "Collecting psutil==5.9.1\n",
            "  Using cached psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 94)) (0.7.0)\n",
            "Collecting pycountry==22.3.5\n",
            "  Using cached pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycparser==2.21 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 96)) (2.21)\n",
            "Collecting pydantic==1.7.4\n",
            "  Using cached pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "Collecting Pygments==2.12.0\n",
            "  Using cached Pygments-2.12.0-py3-none-any.whl (1.1 MB)\n",
            "Collecting pyngrok==5.1.0\n",
            "  Using cached pyngrok-5.1.0.tar.gz (745 kB)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 100)) (3.0.9)\n",
            "Requirement already satisfied: pyrsistent==0.18.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 101)) (0.18.1)\n",
            "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 102)) (1.7.1)\n",
            "Collecting pytextrank==3.2.3\n",
            "  Using cached pytextrank-3.2.3-py3-none-any.whl (30 kB)\n",
            "Collecting python-crfsuite==0.9.8\n",
            "  Using cached python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 105)) (2.8.2)\n",
            "Collecting pytz==2022.1\n",
            "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "Collecting pyvi==0.1.1\n",
            "  Using cached pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "Collecting PyYAML==5.4.1\n",
            "  Using cached PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Collecting pyzmq==23.2.0\n",
            "  Using cached pyzmq-23.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting qtconsole==5.3.1\n",
            "  Using cached qtconsole-5.3.1-py3-none-any.whl (120 kB)\n",
            "Collecting QtPy==2.1.0\n",
            "  Using cached QtPy-2.1.0-py3-none-any.whl (68 kB)\n",
            "Requirement already satisfied: regex==2022.6.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 112)) (2022.6.2)\n",
            "Collecting requests==2.28.1\n",
            "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting rouge==1.0.1\n",
            "  Using cached rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting rouge-metric==1.0.1\n",
            "  Using cached rouge_metric-1.0.1-py3-none-any.whl (151 kB)\n",
            "Collecting rouge-score==0.0.4\n",
            "  Using cached rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting sacrebleu==2.2.0\n",
            "  Using cached sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "Requirement already satisfied: scikit-learn==1.0.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 118)) (1.0.2)\n",
            "Requirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 119)) (1.7.3)\n",
            "Requirement already satisfied: Send2Trash==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 120)) (1.8.0)\n",
            "Collecting sklearn-crfsuite==0.3.6\n",
            "  Using cached sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: smart-open==5.2.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 122)) (5.2.1)\n",
            "Collecting sniffio==1.3.0\n",
            "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting soupsieve==2.3.2.post1\n",
            "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Collecting spacy==3.0.8\n",
            "  Using cached spacy-3.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "Collecting spacy-legacy==3.0.9\n",
            "  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting spacy-loggers==1.0.2\n",
            "  Using cached spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting srsly==2.4.3\n",
            "  Using cached srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "Collecting starlette==0.19.1\n",
            "  Using cached starlette-0.19.1-py3-none-any.whl (63 kB)\n",
            "Collecting summa==1.2.0\n",
            "  Using cached summa-1.2.0.tar.gz (54 kB)\n",
            "Collecting sumy==0.10.0\n",
            "  Using cached sumy-0.10.0-py2.py3-none-any.whl (94 kB)\n",
            "Requirement already satisfied: tabulate==0.8.10 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 132)) (0.8.10)\n",
            "Collecting terminado==0.15.0\n",
            "  Using cached terminado-0.15.0-py3-none-any.whl (16 kB)\n",
            "Collecting thinc==8.0.17\n",
            "  Using cached thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 135)) (3.1.0)\n",
            "Collecting tinycss2==1.1.1\n",
            "  Using cached tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
            "Collecting tokenizers==0.12.1\n",
            "  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "Collecting tornado==6.2\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[K     |████████████████████████████████| 423 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.64.0\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting traitlets==5.3.0\n",
            "  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting transformers==4.21.0\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 64.3 MB/s \n",
            "\u001b[?25hCollecting typer==0.3.2\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Collecting typing-extensions==3.10.0.2\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting underthesea==1.3.4\n",
            "  Downloading underthesea-1.3.4-py3-none-any.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 42.6 MB/s \n",
            "\u001b[?25hCollecting underthesea_core==0.0.4a10\n",
            "  Downloading underthesea_core-0.0.4_alpha.10-cp37-cp37m-manylinux2010_x86_64.whl (581 kB)\n",
            "\u001b[K     |████████████████████████████████| 581 kB 47.3 MB/s \n",
            "\u001b[?25hCollecting Unidecode==1.3.4\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting uritools==4.0.0\n",
            "  Downloading uritools-4.0.0-py3-none-any.whl (10 kB)\n",
            "Collecting urlextract==1.6.0\n",
            "  Downloading urlextract-1.6.0-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3==1.26.9\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.18.3\n",
            "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting vncorenlp==1.0.3\n",
            "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 39.5 MB/s \n",
            "\u001b[?25hCollecting wasabi==0.9.1\n",
            "  Downloading wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 153)) (0.2.5)\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 154)) (0.5.1)\n",
            "Requirement already satisfied: widgetsnbextension==3.6.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/vlsp-final-year/requirements.txt (line 155)) (3.6.1)\n",
            "Collecting zipp==3.8.0\n",
            "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens==2.0.5->-r /content/vlsp-final-year/requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from blis==0.4.1->-r /content/vlsp-final-year/requirements.txt (line 12)) (1.21.6)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2->-r /content/vlsp-final-year/requirements.txt (line 29)) (0.12.1+cu113)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2->-r /content/vlsp-final-year/requirements.txt (line 29)) (1.12.1+cu113)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.5.3->-r /content/vlsp-final-year/requirements.txt (line 35)) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.34.0->-r /content/vlsp-final-year/requirements.txt (line 45)) (57.4.0)\n",
            "Collecting dpcpp_cpp_rt\n",
            "  Downloading dpcpp_cpp_rt-2022.2.0-py2.py3-none-manylinux1_x86_64.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 42.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft==1.3.1->-r /content/vlsp-final-year/requirements.txt (line 66)) (2019.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.28.1->-r /content/vlsp-final-year/requirements.txt (line 113)) (2022.9.24)\n",
            "Collecting intel-cmplr-lib-rt==2022.2.0\n",
            "  Downloading intel_cmplr_lib_rt-2022.2.0-py2.py3-none-manylinux1_x86_64.whl (33.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.1 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting intel-opencl-rt==2022.2.0\n",
            "  Downloading intel_opencl_rt-2022.2.0-py2.py3-none-manylinux1_x86_64.whl (253.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 253.4 MB 43 kB/s \n",
            "\u001b[?25hCollecting intel-cmplr-lic-rt==2022.2.0\n",
            "  Downloading intel_cmplr_lic_rt-2022.2.0-py2.py3-none-manylinux1_x86_64.whl (18 kB)\n",
            "Requirement already satisfied: intel-openmp==2022.2.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft==1.3.1->-r /content/vlsp-final-year/requirements.txt (line 66)) (2022.2.0)\n",
            "Collecting tbb==2021.*\n",
            "  Downloading tbb-2021.7.0-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 52.4 MB/s \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'jupyter-core' candidate (version 4.11.0 at https://files.pythonhosted.org/packages/70/0c/de05ebacf825f55ee4b8a3b2a6ce3e9746c8a9e28dd687762b1a9dd623f9/jupyter_core-4.11.0-py3-none-any.whl#sha256=3ac8784dd2740257a82551fbdaacad48956f1326290fbcc5e47a808347422cee (from https://pypi.org/simple/jupyter-core/) (requires-python:>=3.7))\n",
            "Reason for being yanked: missing top level file jupyter.py\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, breadability, docopt, fastBPE, gdown, pycountry, pyngrok, summa, vncorenlp\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=ad0d2d1ecfda971159bd4f269644df00937ac30f07cbd0a779bbeb0717ac56e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21712 sha256=659c79da3adc0fa9b92240553501ff4ce3dae7afe5f8713eb0ae4793c0ed369b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/bf/51/81d27ad638e1a6dca4f362ecc33d1e2c764b8ea7ec751b8fc1\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=0af294704283c574dad3ef7e55afc4c6a0fb1fcf7922536f1288578372cadb14\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=483892 sha256=358b743c36cd445ef74532624d86cf81189be6fbfee52305cd270b29393fda36\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.5.3-py3-none-any.whl size=14841 sha256=603e77f0b1fe15ed37fac4d968ff462d76220147deebb911cd4013690df72965\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/8d/0b/bdcd83555c3555f91a33f6c2384428d9f163c7d75ab0d272b4\n",
            "  Building wheel for pycountry (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681845 sha256=43a8418d60e8560ee5c44f4d484d90cf4899d02bfd9028b06b6e4fc548bfb72b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/06/e8/7ee176e95ea9a8a8c3b3afcb1869f20adbd42413d4611c6eb4\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=6c62b43e30fb0b2e4e730300c441f52b460fdf612e4e5a9208a3592009766619\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54412 sha256=58fd67c1b14be1b0189d2325de1cd133de91cf5345512db2be10c6834f67289a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/64/ac/7b443477588d365ef37ada30d456bdf5f07dc5be9f6324cb6e\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=cd708ecda1786bbe19600ad830dda4c9daefe95a085205f61a9a584f3bc0d742\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n",
            "Successfully built antlr4-python3-runtime breadability docopt fastBPE gdown pycountry pyngrok summa vncorenlp\n",
            "Installing collected packages: zipp, typing-extensions, traitlets, importlib-resources, importlib-metadata, attrs, tornado, pyzmq, nest-asyncio, jupyter-core, jsonschema, fastjsonschema, soupsieve, Pygments, prompt-toolkit, nbformat, matplotlib-inline, MarkupSafe, jupyter-client, jedi, decorator, tinycss2, psutil, nbclient, jupyterlab-pygments, Jinja2, ipython, debugpy, beautifulsoup4, argon2-cffi-bindings, terminado, prometheus-client, nbconvert, murmurhash, ipykernel, cymem, catalogue, argon2-cffi, wasabi, urllib3, typer, tbb, srsly, sniffio, PyYAML, pytz, pydantic, preshed, Pillow, notebook, kiwisolver, intel-cmplr-lic-rt, idna, fonttools, charset-normalizer, blis, uritools, tqdm, thinc, spacy-legacy, requests, QtPy, python-crfsuite, portalocker, platformdirs, path, omegaconf, matplotlib, jupyterlab-widgets, joblib, intel-opencl-rt, intel-cmplr-lib-rt, filelock, executing, docopt, colorama, chardet, asttokens, anyio, antlr4-python3-runtime, urlextract, Unidecode, underthesea-core, tokenizers, starlette, spacy, sklearn-crfsuite, sacrebleu, qtconsole, pycountry, path.py, jupyter-console, icecream, hydra-core, huggingface-hub, h11, graphviz, dpcpp-cpp-rt, breadability, bitarray, absl-py, vncorenlp, uvicorn, underthesea, transformers, sumy, summa, spacy-loggers, rouge-score, rouge-metric, rouge, pyvi, pytextrank, pyngrok, plac, mkl-service, mkl-fft, lexrank, jupyter, gdown, fastBPE, fastapi, fairseq\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.10.0\n",
            "    Uninstalling zipp-3.10.0:\n",
            "      Successfully uninstalled zipp-3.10.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.10.0\n",
            "    Uninstalling importlib-resources-5.10.0:\n",
            "      Successfully uninstalled importlib-resources-5.10.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.13.0\n",
            "    Uninstalling importlib-metadata-4.13.0:\n",
            "      Successfully uninstalled importlib-metadata-4.13.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 22.1.0\n",
            "    Uninstalling attrs-22.1.0:\n",
            "      Successfully uninstalled attrs-22.1.0\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.0.4\n",
            "    Uninstalling tornado-6.0.4:\n",
            "      Successfully uninstalled tornado-6.0.4\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 23.2.1\n",
            "    Uninstalling pyzmq-23.2.1:\n",
            "      Successfully uninstalled pyzmq-23.2.1\n",
            "  Attempting uninstall: jupyter-core\n",
            "    Found existing installation: jupyter-core 4.11.2\n",
            "    Uninstalling jupyter-core-4.11.2:\n",
            "      Successfully uninstalled jupyter-core-4.11.2\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "  Attempting uninstall: fastjsonschema\n",
            "    Found existing installation: fastjsonschema 2.16.2\n",
            "    Uninstalling fastjsonschema-2.16.2:\n",
            "      Successfully uninstalled fastjsonschema-2.16.2\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 2.0.10\n",
            "    Uninstalling prompt-toolkit-2.0.10:\n",
            "      Successfully uninstalled prompt-toolkit-2.0.10\n",
            "  Attempting uninstall: nbformat\n",
            "    Found existing installation: nbformat 5.7.0\n",
            "    Uninstalling nbformat-5.7.0:\n",
            "      Successfully uninstalled nbformat-5.7.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.9.0\n",
            "    Uninstalling ipython-7.9.0:\n",
            "      Successfully uninstalled ipython-7.9.0\n",
            "  Attempting uninstall: debugpy\n",
            "    Found existing installation: debugpy 1.0.0\n",
            "    Uninstalling debugpy-1.0.0:\n",
            "      Successfully uninstalled debugpy-1.0.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: terminado\n",
            "    Found existing installation: terminado 0.13.3\n",
            "    Uninstalling terminado-0.13.3:\n",
            "      Successfully uninstalled terminado-0.13.3\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.15.0\n",
            "    Uninstalling prometheus-client-0.15.0:\n",
            "      Successfully uninstalled prometheus-client-0.15.0\n",
            "  Attempting uninstall: nbconvert\n",
            "    Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "  Attempting uninstall: murmurhash\n",
            "    Found existing installation: murmurhash 1.0.9\n",
            "    Uninstalling murmurhash-1.0.9:\n",
            "      Successfully uninstalled murmurhash-1.0.9\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.3.4\n",
            "    Uninstalling ipykernel-5.3.4:\n",
            "      Successfully uninstalled ipykernel-5.3.4\n",
            "  Attempting uninstall: cymem\n",
            "    Found existing installation: cymem 2.0.7\n",
            "    Uninstalling cymem-2.0.7:\n",
            "      Successfully uninstalled cymem-2.0.7\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 0.10.1\n",
            "    Uninstalling wasabi-0.10.1:\n",
            "      Successfully uninstalled wasabi-0.10.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.4.2\n",
            "    Uninstalling typer-0.4.2:\n",
            "      Successfully uninstalled typer-0.4.2\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.5\n",
            "    Uninstalling srsly-2.4.5:\n",
            "      Successfully uninstalled srsly-2.4.5\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.5\n",
            "    Uninstalling pytz-2022.5:\n",
            "      Successfully uninstalled pytz-2022.5\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.2\n",
            "    Uninstalling pydantic-1.10.2:\n",
            "      Successfully uninstalled pydantic-1.10.2\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.8\n",
            "    Uninstalling preshed-3.0.8:\n",
            "      Successfully uninstalled preshed-3.0.8\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 5.7.16\n",
            "    Uninstalling notebook-5.7.16:\n",
            "      Successfully uninstalled notebook-5.7.16\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.4\n",
            "    Uninstalling kiwisolver-1.4.4:\n",
            "      Successfully uninstalled kiwisolver-1.4.4\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.1.1\n",
            "    Uninstalling charset-normalizer-2.1.1:\n",
            "      Successfully uninstalled charset-normalizer-2.1.1\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.9\n",
            "    Uninstalling blis-0.7.9:\n",
            "      Successfully uninstalled blis-0.7.9\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.5\n",
            "    Uninstalling thinc-8.1.5:\n",
            "      Successfully uninstalled thinc-8.1.5\n",
            "  Attempting uninstall: spacy-legacy\n",
            "    Found existing installation: spacy-legacy 3.0.10\n",
            "    Uninstalling spacy-legacy-3.0.10:\n",
            "      Successfully uninstalled spacy-legacy-3.0.10\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab-widgets 3.0.3\n",
            "    Uninstalling jupyterlab-widgets-3.0.3:\n",
            "      Successfully uninstalled jupyterlab-widgets-3.0.3\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.2.0\n",
            "    Uninstalling joblib-1.2.0:\n",
            "      Successfully uninstalled joblib-1.2.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.8.0\n",
            "    Uninstalling filelock-3.8.0:\n",
            "      Successfully uninstalled filelock-3.8.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.2\n",
            "    Uninstalling spacy-3.4.2:\n",
            "      Successfully uninstalled spacy-3.4.2\n",
            "  Attempting uninstall: jupyter-console\n",
            "    Found existing installation: jupyter-console 6.1.0\n",
            "    Uninstalling jupyter-console-6.1.0:\n",
            "      Successfully uninstalled jupyter-console-6.1.0\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "  Attempting uninstall: spacy-loggers\n",
            "    Found existing installation: spacy-loggers 1.0.3\n",
            "    Uninstalling spacy-loggers-1.0.3:\n",
            "      Successfully uninstalled spacy-loggers-1.0.3\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "moviepy 0.2.3.5 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=5.3.4, but you have ipykernel 6.15.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook~=5.7.16, but you have notebook 6.4.12 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=6.0.4, but you have tornado 6.2 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.0.8 which is incompatible.\u001b[0m\n",
            "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.1 Pillow-9.0.1 PyYAML-5.4.1 Pygments-2.12.0 QtPy-2.1.0 Unidecode-1.3.4 absl-py-1.1.0 antlr4-python3-runtime-4.8 anyio-3.6.1 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 asttokens-2.0.5 attrs-21.4.0 beautifulsoup4-4.11.1 bitarray-2.6.0 blis-0.4.1 breadability-0.1.20 catalogue-2.0.7 chardet-5.0.0 charset-normalizer-2.1.0 colorama-0.4.5 cymem-2.0.6 debugpy-1.6.2 decorator-5.1.1 docopt-0.6.2 dpcpp-cpp-rt-2022.2.0 executing-0.8.3 fairseq-0.12.2 fastBPE-0.1.0 fastapi-0.81.0 fastjsonschema-2.15.3 filelock-3.7.1 fonttools-4.33.3 gdown-4.5.3 graphviz-0.20 h11-0.13.0 huggingface-hub-0.8.1 hydra-core-1.0.7 icecream-2.1.2 idna-3.3 importlib-metadata-4.12.0 importlib-resources-5.8.0 intel-cmplr-lib-rt-2022.2.0 intel-cmplr-lic-rt-2022.2.0 intel-opencl-rt-2022.2.0 ipykernel-6.15.0 ipython-7.34.0 jedi-0.18.1 joblib-1.1.0 jsonschema-4.6.2 jupyter-1.0.0 jupyter-client-7.3.4 jupyter-console-6.4.4 jupyter-core-4.11.0 jupyterlab-pygments-0.2.2 jupyterlab-widgets-1.1.1 kiwisolver-1.4.3 lexrank-0.1.0 matplotlib-3.5.2 matplotlib-inline-0.1.3 mkl-fft-1.3.1 mkl-service-2.4.0 murmurhash-1.0.7 nbclient-0.6.6 nbconvert-6.5.0 nbformat-5.4.0 nest-asyncio-1.5.5 notebook-6.4.12 omegaconf-2.0.6 path-16.4.0 path.py-12.5.0 plac-1.1.3 platformdirs-2.5.2 portalocker-2.5.1 preshed-3.0.6 prometheus-client-0.14.1 prompt-toolkit-3.0.30 psutil-5.9.1 pycountry-22.3.5 pydantic-1.7.4 pyngrok-5.1.0 pytextrank-3.2.3 python-crfsuite-0.9.8 pytz-2022.1 pyvi-0.1.1 pyzmq-23.2.0 qtconsole-5.3.1 requests-2.28.1 rouge-1.0.1 rouge-metric-1.0.1 rouge-score-0.0.4 sacrebleu-2.2.0 sklearn-crfsuite-0.3.6 sniffio-1.3.0 soupsieve-2.3.2.post1 spacy-3.0.8 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 starlette-0.19.1 summa-1.2.0 sumy-0.10.0 tbb-2021.7.0 terminado-0.15.0 thinc-8.0.17 tinycss2-1.1.1 tokenizers-0.12.1 tornado-6.2 tqdm-4.64.0 traitlets-5.3.0 transformers-4.21.0 typer-0.3.2 typing-extensions-3.10.0.2 underthesea-1.3.4 underthesea-core-0.0.4a10 uritools-4.0.0 urlextract-1.6.0 urllib3-1.26.9 uvicorn-0.18.3 vncorenlp-1.0.3 wasabi-0.9.1 zipp-3.8.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "PIL",
                  "chardet",
                  "debugpy",
                  "decorator",
                  "idna",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "prompt_toolkit",
                  "psutil",
                  "pygments",
                  "pytz",
                  "requests",
                  "tornado",
                  "tqdm",
                  "typing_extensions",
                  "urllib3",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r /content/vlsp-final-year/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Qx3KqFjG2S"
      },
      "source": [
        "Chỉnh sửa các nội dung trong file sau để đảm bảo khả năng chạy được "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLZwfczijRMI"
      },
      "source": [
        "# Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ4_MnpUsF9S",
        "outputId": "5a3a3ae6-8fdf-4274-f81d-e4942dfc05b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/vlsp-final-year\n"
          ]
        }
      ],
      "source": [
        "%cd /content/vlsp-final-year/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im3nSSnDsORH",
        "outputId": "c90b3799-061b-4535-91f6-1a4321e370b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/vlsp-final-year\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfVL4pU-q0zM",
        "outputId": "c197a2e6-fcd5-4cd0-808b-a48f1aa17cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of cluster:  200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "200it [00:53,  3.75it/s]\n",
            "WARNING:root:[PIPELINE] - Load train set from /content/vlsp-final-year/dataset/vlsp_2022_abmusu_train_data_new.jsonl. Done.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of cluster:  100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [00:25,  3.86it/s]\n",
            "WARNING:root:[PIPELINE] - Load valid set from /content/vlsp-final-year/dataset/vlsp_2022_abmusu_train_data_new.jsonl. Done.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of cluster:  300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "300it [01:16,  3.93it/s]\n",
            "WARNING:root:[PIPELINE] - Load test set from /content/vlsp-final-year/dataset/vlsp_2022_abmusu_train_data_new.jsonl. Done.\n",
            "WARNING:root:Start create SBERT embedding\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training in pipeline:  rerun-after-take-summary\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading codes from /content/vlsp-final-year/external/vn_sbert_deploy/bpe/bpe.codes ...\n",
            "Read 64000 codes from the codes file.\n",
            "WARNING:root:Create SBERT embedding complete\n",
            "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
            "WARNING:root:Start create SBERT embedding\n",
            "Loading codes from /content/vlsp-final-year/external/vn_sbert_deploy/bpe/bpe.codes ...\n",
            "Read 64000 codes from the codes file.\n",
            "WARNING:root:Create SBERT embedding complete\n",
            "WARNING:root:MMR-init: Model created\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_train' - Start training.\n",
            "100%|██████████| 200/200 [29:53<00:00,  8.97s/it]\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_train' - Training complete. Saving report.\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster' - Saving report complete.\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_valid' - Start training on validate set.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start to save report rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_train to: /content/vlsp-final-year/data/result/rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster\n",
            "Save report complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [14:17<00:00,  8.57s/it]\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_valid' - Training on valid set complete. Saving report.\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_valid' - Saving valid report complete.\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_test' - Test dataset not found.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start to save report rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_valid to: /content/vlsp-final-year/data/result/rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster\n",
            "Save report complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Start create SBERT embedding\n",
            "Loading codes from /content/vlsp-final-year/external/vn_sbert_deploy/bpe/bpe.codes ...\n",
            "Read 64000 codes from the codes file.\n",
            "WARNING:root:Create SBERT embedding complete\n",
            "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
            "WARNING:root:Start create SBERT embedding\n",
            "Loading codes from /content/vlsp-final-year/external/vn_sbert_deploy/bpe/bpe.codes ...\n",
            "Read 64000 codes from the codes file.\n",
            "WARNING:root:Create SBERT embedding complete\n",
            "WARNING:root:MMR-init: Model created\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_test' - Start predict on test.\n",
            "100%|██████████| 300/300 [40:35<00:00,  8.12s/it]\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_test' - Predict on test complete. Saving report.\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_best_title_8_0.1_cluster_test' - Saving test report complete.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start write to txt\n",
            "Done write to txt\n",
            "Start training in pipeline:  rerun-after-take-summary\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Start create SBERT embedding\n",
            "Loading codes from /content/vlsp-final-year/external/vn_sbert_deploy/bpe/bpe.codes ...\n",
            "Read 64000 codes from the codes file.\n",
            "WARNING:root:Create SBERT embedding complete\n",
            "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
            "WARNING:root:Start create SBERT embedding\n",
            "Loading codes from /content/vlsp-final-year/external/vn_sbert_deploy/bpe/bpe.codes ...\n",
            "Read 64000 codes from the codes file.\n",
            "WARNING:root:Create SBERT embedding complete\n",
            "WARNING:root:MMR-init: Model created\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_anchor_8_0.1_cluster_train' - Start training.\n",
            " 14%|█▍        | 28/200 [04:27<25:44,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed title:  \n",
            "Failed title:  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 194/200 [28:32<00:47,  7.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed title:  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [29:15<00:00,  8.78s/it]\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_anchor_8_0.1_cluster_train' - Training complete. Saving report.\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_anchor_8_0.1_cluster' - Saving report complete.\n",
            "WARNING:root:[JOB] 'rerun-after-take-summary_mmr_query_anchor_8_0.1_cluster_valid' - Start training on validate set.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start to save report rerun-after-take-summary_mmr_query_anchor_8_0.1_cluster_train to: /content/vlsp-final-year/data/result/rerun-after-take-summary_mmr_query_anchor_8_0.1_cluster\n",
            "Save report complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 15/100 [02:23<10:21,  7.31s/it]"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import argparse\n",
        "\n",
        "from src.config.config import  load_config_from_json\n",
        "from src.loader.class_loader import load_cluster\n",
        "from src.pipeline.pipeline import Pipeline\n",
        "\n",
        "\n",
        "config = load_config_from_json(\"/content/vlsp-final-year/env.json\")\n",
        "\n",
        "train_path = config.train_path \n",
        "valid_path = config.valid_path \n",
        "test_path = \"/content/vlsp-final-year/dataset/vlsp_abmusu_test_data.jsonl\"\n",
        "\n",
        "\n",
        "# train_set = load_cluster(\n",
        "#     config.train_path\n",
        "# )\n",
        "try:\n",
        "    train_set = load_cluster(\n",
        "        train_path\n",
        "    )\n",
        "    logging.warning(\"[PIPELINE] - Load train set from {}. Done.\".format(train_path))\n",
        "except Exception as e:\n",
        "    train_set = None\n",
        "    logging.warning(\"[PIPELINE] - Load train set from {}. Failed. Using None.\".format(train_path))\n",
        "\n",
        "try:\n",
        "    valid_set = load_cluster(\n",
        "        valid_path\n",
        "    )\n",
        "    logging.warning(\"[PIPELINE] - Load valid set from {}. Done.\".format(train_path))\n",
        "except Exception as e:\n",
        "    valid_set = None\n",
        "    logging.warning(\"[PIPELINE] - Load valid set from {}. Failed. Using None.\".format(train_path))\n",
        "\n",
        "try:\n",
        "    test_set = load_cluster(\n",
        "        test_path\n",
        "    )\n",
        "    logging.warning(\"[PIPELINE] - Load test set from {}. Done.\".format(train_path))\n",
        "except Exception as e:\n",
        "    test_set = None\n",
        "    logging.warning(\"[PIPELINE] - Load test set from {}. Failed. Using None.\".format(train_path))\n",
        "\n",
        "# add index run here \n",
        "\n",
        "index_set = [10, 11]\n",
        "\n",
        "for idx in index_set:\n",
        "    try:\n",
        "        pipeline0 = Pipeline(config, idx)\n",
        "        try:\n",
        "            pipeline0.training(train_set, valid_set)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "        pipeline0.predict(test_set)\n",
        "    except Exception as e:\n",
        "        logging.error(\"[PIPELINE] - Init pipeline failed, error: \", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn-6Efmluteg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1bcyJnVrI3EHCDDSkKLMGNjUZksOPgdhe",
      "authorship_tag": "ABX9TyOJZxLDX0frVqD3tGtqeZ7u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}