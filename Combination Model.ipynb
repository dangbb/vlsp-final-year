{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f933ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import traceback\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.config.config import Config, load_config_from_json\n",
    "from src.evaluate.rouge_evaluator import ScoreSummary\n",
    "from src.loader.class_loader import Dataset, SOURCE, Cluster\n",
    "from src.utils.factory import create_model, create_evaluator\n",
    "from src.model.sds.combination import CombinationRanker\n",
    "from src.loader.class_loader import load_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d2a371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cluster:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:38,  5.17it/s]\n",
      "WARNING:root:[PIPELINE] - Load train set from /home/dang/vlsp-final-year/dataset/vlsp_2022_abmusu_train_data_new.jsonl. Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cluster:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:18,  5.45it/s]\n",
      "WARNING:root:[PIPELINE] - Load valid set from /home/dang/vlsp-final-year/dataset/vlsp_2022_abmusu_validation_data_new.jsonl. Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cluster:  300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [00:50,  5.98it/s]\n",
      "WARNING:root:[PIPELINE] - Load test set from /home/dang/vlsp-final-year/dataset/vlsp_abmusu_test_data.jsonl. Done.\n"
     ]
    }
   ],
   "source": [
    "config = load_config_from_json()\n",
    "\n",
    "try:\n",
    "    train_set = load_cluster(\n",
    "        config.train_path,\n",
    "    )\n",
    "    logging.warning(\"[PIPELINE] - Load train set from {}. Done.\".format(config.train_path))\n",
    "except Exception as e:\n",
    "    train_set = None\n",
    "    logging.warning(\"[PIPELINE] - Load train set from {}. Failed. Using None.\".format(config.train_path))\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    valid_set = load_cluster(\n",
    "        config.valid_path,\n",
    "    )\n",
    "    logging.warning(\"[PIPELINE] - Load valid set from {}. Done.\".format(config.valid_path))\n",
    "except Exception as e:\n",
    "    valid_set = None\n",
    "    logging.warning(\"[PIPELINE] - Load valid set from {}. Failed. Using None.\".format(config.valid_path))\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    test_set = load_cluster(\n",
    "        \"/home/dang/vlsp-final-year/dataset/vlsp_abmusu_test_data.jsonl\",\n",
    "    )\n",
    "    logging.warning(\"[PIPELINE] - Load test set from {}. Done.\".format(\"/home/dang/vlsp-final-year/dataset/vlsp_abmusu_test_data.jsonl\"))\n",
    "except Exception as e:\n",
    "    test_set = None\n",
    "    logging.warning(\"[PIPELINE] - Load test set from {}. Failed. Using None.\".format(\"/home/dang/vlsp-final-year/dataset/vlsp_abmusu_test_data.jsonl\"))\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789a3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.set_source(SOURCE.SENT_SPLITTED_TOKEN.value)\n",
    "valid_set.set_source(SOURCE.SENT_SPLITTED_TOKEN.value)\n",
    "test_set.set_source(SOURCE.SENT_SPLITTED_TOKEN.value)\n",
    "\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "test_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ea3baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:ComnbinationRanker-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:TFIDF-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:TFIDF-init: Model created\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n",
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n",
      "WARNING:root:ComnbinationRanker-init: Model created\n"
     ]
    }
   ],
   "source": [
    "from src.model.sds.combination import CombinationRanker\n",
    "\n",
    "config = load_config_from_json()\n",
    "model_config = config.models[15]\n",
    "\n",
    "model = CombinationRanker(model_config)\n",
    "model.training(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31719922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get local score on train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 200/200 [00:44<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get local score on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:20<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get local score on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 300/300 [00:59<00:00,  5.07it/s]\n"
     ]
    }
   ],
   "source": [
    "weight = {\n",
    "    \"tfidf\": 0.1,\n",
    "    \"lexrank\": 0.1,\n",
    "    \"textrank\": 0.1\n",
    "}\n",
    "    \n",
    "print(\"get local score on train set\")\n",
    "for cluster in tqdm(train_set.clusters):\n",
    "    document_score = []\n",
    "\n",
    "    for doc in cluster.documents:\n",
    "        document_score.append(model.get_score(doc.get_all_sents(), 1))\n",
    "\n",
    "    train_scores.append(document_score)\n",
    "\n",
    "print(\"get local score on valid set\")\n",
    "for cluster in tqdm(valid_set.clusters):\n",
    "    document_score = []\n",
    "\n",
    "    for doc in cluster.documents:\n",
    "        document_score.append(model.get_score(doc.get_all_sents(), 1))\n",
    "\n",
    "    valid_scores.append(document_score)\n",
    "    \n",
    "print(\"get local score on test set\")\n",
    "for cluster in tqdm(test_set.clusters):\n",
    "    document_score = []\n",
    "\n",
    "    for doc in cluster.documents:\n",
    "        document_score.append(model.get_score(doc.get_all_sents(), 1))\n",
    "\n",
    "    test_scores.append(document_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40922689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate.rouge_evaluator import RougeScore\n",
    "\n",
    "class RougeScoreStorage:\n",
    "    def __init__(self):\n",
    "        self.df = pd.DataFrame(columns=[\n",
    "            'cluster_id',\n",
    "            'rouge_1_p',\n",
    "            'rouge_1_r',\n",
    "            'rouge_1_f',\n",
    "            'rouge_2_p',\n",
    "            'rouge_2_r',\n",
    "            'rouge_2_f',\n",
    "            'rouge_l_p',\n",
    "            'rouge_l_r',\n",
    "            'rouge_l_f',\n",
    "        ])\n",
    "    \n",
    "    def add_score(self, cluster_id: int, score: RougeScore):\n",
    "        self.df = self.df.append({\n",
    "            'cluster_id': cluster_id,\n",
    "            'rouge_1_p': score.rouge1.p,\n",
    "            'rouge_1_r': score.rouge1.r,\n",
    "            'rouge_1_f': score.rouge1.f1,\n",
    "            'rouge_2_p': score.rouge2.p,\n",
    "            'rouge_2_r': score.rouge2.r,\n",
    "            'rouge_2_f': score.rouge2.f1,\n",
    "            'rouge_l_p': score.rougeL.p,\n",
    "            'rouge_l_r': score.rougeL.r,\n",
    "            'rouge_l_f': score.rougeL.f1,\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    def summary_score(self):\n",
    "        summary_df = pd.DataFrame(columns=[\n",
    "            'name',\n",
    "            'mean',\n",
    "            'min',\n",
    "            'max',\n",
    "            'std',\n",
    "        ])\n",
    "\n",
    "        metric_cols = [\n",
    "            'rouge_1_p',\n",
    "            'rouge_1_r',\n",
    "            'rouge_1_f',\n",
    "            'rouge_2_p',\n",
    "            'rouge_2_r',\n",
    "            'rouge_2_f',\n",
    "            'rouge_l_p',\n",
    "            'rouge_l_r',\n",
    "            'rouge_l_f', ]\n",
    "\n",
    "        for col in metric_cols:\n",
    "            describe = self.df[col].describe()\n",
    "            summary_df = summary_df.append({\n",
    "                'name': col,\n",
    "                'mean': describe['mean'],\n",
    "                'min': describe['min'],\n",
    "                'max': describe['max'],\n",
    "                'std': describe['std'],\n",
    "            }, ignore_index=True)\n",
    "        \n",
    "        return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684de60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate.rouge_evaluator import ScoreSummary\n",
    "from src.utils.factory import create_model, create_evaluator\n",
    "from src.model.mmr_query import MMRSummarizerQuery\n",
    "\n",
    "evaluator = create_evaluator(config.eval_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b62c798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sent = [11, 0.2]\n",
    "\n",
    "def get_rouge_score(weights, sigma):\n",
    "    local_config = config.models[15]\n",
    "    local_config.sigma = sigma\n",
    "    \n",
    "    mmr = MMRSummarizerQuery(local_config) \n",
    "    \n",
    "    train_storage = RougeScoreStorage()\n",
    "    valid_storage = RougeScoreStorage()\n",
    "    \n",
    "    print(\"Test on training set\")\n",
    "    \n",
    "    \"\"\"train_set.set_source(SOURCE.SENT_SPLITTED_TEXT.value)\n",
    "    for idx, cluster in tqdm(enumerate(train_set.clusters)):\n",
    "        chosen_sent = [] \n",
    "\n",
    "        sent_count = len(cluster.get_all_sents())\n",
    "        for SENT_COUNT in n_sent:\n",
    "            if 0 <= SENT_COUNT < 1:\n",
    "                sent_count = min(int(math.ceil(len(cluster.get_all_sents()) * SENT_COUNT)), sent_count)\n",
    "            else:\n",
    "                sent_count = min(int(SENT_COUNT), sent_count)\n",
    "\n",
    "\n",
    "        for idxc, doc in enumerate(cluster.documents):\n",
    "            doc.set_source(SOURCE.SENT_SPLITTED_TEXT.value)\n",
    "            sents = doc.get_all_sents()\n",
    "\n",
    "            scores = train_scores[idx][idxc]\n",
    "\n",
    "            combine_score = np.zeros((len(scores[\"tfidf\"])), dtype=float)\n",
    "\n",
    "            for key in weights.keys():\n",
    "                combine_score += scores[key] * weights[key]\n",
    "\n",
    "            if (sent_count >= len(combine_score)):\n",
    "                chosen_idx = list(range(len(combine_score)))\n",
    "            else:\n",
    "                chosen_idx = np.argpartition(combine_score, -sent_count)[-sent_count:]\n",
    "\n",
    "            for i in chosen_idx:\n",
    "                chosen_sent.append(sents[i]) \n",
    "\n",
    "        pred_sent, _ = mmr(chosen_sent, sent_count, cluster.get_all_anchor())\n",
    "\n",
    "        train_storage.add_score(\n",
    "            cluster.cluster_idx,\n",
    "            evaluator(\n",
    "                '.'.join(pred_sent),\n",
    "                '.'.join(cluster.get_summary()),\n",
    "            )\n",
    "        )\"\"\"\n",
    "    \n",
    "    print(\"Test on valid set\")\n",
    "    \n",
    "    valid_set.set_source(SOURCE.SENT_SPLITTED_TEXT.value)\n",
    "    for idx, cluster in tqdm(enumerate(valid_set.clusters)):\n",
    "        chosen_sent = [] \n",
    "        \n",
    "        sent_count = len(cluster.get_all_sents())\n",
    "        for SENT_COUNT in n_sent:\n",
    "            if 0 <= SENT_COUNT < 1:\n",
    "                sent_count = min(int(math.ceil(len(cluster.get_all_sents()) * SENT_COUNT)), sent_count)\n",
    "            else:\n",
    "                sent_count = min(int(SENT_COUNT), sent_count)\n",
    "        \n",
    "        \n",
    "        for idxc, doc in enumerate(cluster.documents):\n",
    "            doc.set_source(SOURCE.SENT_SPLITTED_TOKEN.value)\n",
    "            sents = doc.get_all_sents()\n",
    "            \n",
    "            scores = valid_scores[idx][idxc]\n",
    "            \n",
    "            combine_score = np.zeros((len(scores[\"tfidf\"])), dtype=float)\n",
    "        \n",
    "            for key in weights.keys():\n",
    "                combine_score += scores[key] * weights[key]\n",
    "            \n",
    "            if (sent_count >= len(combine_score)):\n",
    "                chosen_idx = list(range(len(combine_score)))\n",
    "            else:\n",
    "                chosen_idx = np.argpartition(combine_score, -sent_count)[-sent_count:]\n",
    "            \n",
    "            for i in chosen_idx:\n",
    "                chosen_sent.append(sents[i]) \n",
    "                \n",
    "        pred_sent, _ = mmr(chosen_sent, sent_count, cluster.get_all_anchor())\n",
    "        \n",
    "        cluster.set_source(SOURCE.SENT_SPLITTED_TOKEN.value)\n",
    "        valid_storage.add_score(\n",
    "            cluster.cluster_idx,\n",
    "            evaluator(\n",
    "                '.'.join(pred_sent),\n",
    "                '.'.join(cluster.get_summary()),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    print(\"Using weight\\n\", weights)\n",
    "    print(\"Sigma: \", sigma)\n",
    "    # print(\"Train result\\n\", train_storage.summary_score())\n",
    "    print(\"Valid result\\n\", valid_storage.summary_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b747eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge_score_and_saved(weights, sigma):\n",
    "    local_config = config.models[15]\n",
    "    local_config.sigma = sigma\n",
    "    \n",
    "    mmr = MMRSummarizerQuery(local_config) \n",
    "    \n",
    "    train_storage = RougeScoreStorage()\n",
    "    valid_storage = RougeScoreStorage()\n",
    "    \n",
    "    print(\"Test on training set\")\n",
    "    \n",
    "    \"\"\"train_set.set_source(SOURCE.SENT_SPLITTED_TEXT.value)\n",
    "    for idx, cluster in tqdm(enumerate(train_set.clusters)):\n",
    "        chosen_sent = [] \n",
    "\n",
    "        sent_count = len(cluster.get_all_sents())\n",
    "        for SENT_COUNT in n_sent:\n",
    "            if 0 <= SENT_COUNT < 1:\n",
    "                sent_count = min(int(math.ceil(len(cluster.get_all_sents()) * SENT_COUNT)), sent_count)\n",
    "            else:\n",
    "                sent_count = min(int(SENT_COUNT), sent_count)\n",
    "\n",
    "\n",
    "        for idxc, doc in enumerate(cluster.documents):\n",
    "            doc.set_source(SOURCE.SENT_SPLITTED_TEXT.value)\n",
    "            sents = doc.get_all_sents()\n",
    "\n",
    "            scores = train_scores[idx][idxc]\n",
    "\n",
    "            combine_score = np.zeros((len(scores[\"tfidf\"])), dtype=float)\n",
    "\n",
    "            for key in weights.keys():\n",
    "                combine_score += scores[key] * weights[key]\n",
    "\n",
    "            if (sent_count >= len(combine_score)):\n",
    "                chosen_idx = list(range(len(combine_score)))\n",
    "            else:\n",
    "                chosen_idx = np.argpartition(combine_score, -sent_count)[-sent_count:]\n",
    "\n",
    "            for i in chosen_idx:\n",
    "                chosen_sent.append(sents[i]) \n",
    "\n",
    "        pred_sent, _ = mmr(chosen_sent, sent_count, cluster.get_all_anchor())\n",
    "\n",
    "        train_storage.add_score(\n",
    "            cluster.cluster_idx,\n",
    "            evaluator(\n",
    "                '.'.join(pred_sent),\n",
    "                '.'.join(cluster.get_summary()),\n",
    "            )\n",
    "        )\"\"\"\n",
    "    \n",
    "    print(\"Test on valid set\")\n",
    "    \n",
    "    valid_set.set_source(SOURCE.SENT_SPLITTED_TEXT.value)\n",
    "    for idx, cluster in tqdm(enumerate(valid_set.clusters)):\n",
    "        chosen_sent = [] \n",
    "        \n",
    "        sent_count = len(cluster.get_all_sents())\n",
    "        for SENT_COUNT in n_sent:\n",
    "            if 0 <= SENT_COUNT < 1:\n",
    "                sent_count = min(int(math.ceil(len(cluster.get_all_sents()) * SENT_COUNT)), sent_count)\n",
    "            else:\n",
    "                sent_count = min(int(SENT_COUNT), sent_count)\n",
    "        \n",
    "        \n",
    "        for idxc, doc in enumerate(cluster.documents):\n",
    "            doc.set_source(SOURCE.SENT_SPLITTED_TOKEN.value)\n",
    "            sents = doc.get_all_sents()\n",
    "            \n",
    "            scores = valid_scores[idx][idxc]\n",
    "            \n",
    "            combine_score = np.zeros((len(scores[\"tfidf\"])), dtype=float)\n",
    "        \n",
    "            for key in weights.keys():\n",
    "                combine_score += scores[key] * weights[key]\n",
    "            \n",
    "            if (sent_count >= len(combine_score)):\n",
    "                chosen_idx = list(range(len(combine_score)))\n",
    "            else:\n",
    "                chosen_idx = np.argpartition(combine_score, -sent_count)[-sent_count:]\n",
    "            \n",
    "            for i in chosen_idx:\n",
    "                chosen_sent.append(sents[i]) \n",
    "                \n",
    "        pred_sent, _ = mmr(chosen_sent, sent_count, cluster.get_all_anchor())\n",
    "        \n",
    "        cluster.set_source(SOURCE.SENT_SPLITTED_TOKEN.value)\n",
    "        valid_storage.add_score(\n",
    "            cluster.cluster_idx,\n",
    "            evaluator(\n",
    "                '.'.join(pred_sent),\n",
    "                '.'.join(cluster.get_summary()),\n",
    "            )\n",
    "        )\n",
    "     \n",
    "    print(\"Predict on test set\")\n",
    "    \n",
    "    test_set.set_source(SOURCE.SENT_SPLITTED_TEXT.value)\n",
    "    predictions = []\n",
    "    \n",
    "    for idx, cluster in tqdm(enumerate(test_set.clusters)):\n",
    "        chosen_sent = [] \n",
    "        \n",
    "        sent_count = len(cluster.get_all_sents())\n",
    "        for SENT_COUNT in n_sent:\n",
    "            if 0 <= SENT_COUNT < 1:\n",
    "                sent_count = min(int(math.ceil(len(cluster.get_all_sents()) * SENT_COUNT)), sent_count)\n",
    "            else:\n",
    "                sent_count = min(int(SENT_COUNT), sent_count)\n",
    "        \n",
    "        \n",
    "        for idxc, doc in enumerate(cluster.documents):\n",
    "            doc.set_source(SOURCE.SENT_SPLITTED_TEXT.value)\n",
    "            sents = doc.get_all_sents()\n",
    "            \n",
    "            scores = test_scores[idx][idxc]\n",
    "            \n",
    "            combine_score = np.zeros((len(scores[\"tfidf\"])), dtype=float)\n",
    "        \n",
    "            for key in weights.keys():\n",
    "                combine_score += scores[key] * weights[key]\n",
    "            \n",
    "            if (sent_count >= len(combine_score)):\n",
    "                chosen_idx = list(range(len(combine_score)))\n",
    "            else:\n",
    "                chosen_idx = np.argpartition(combine_score, -sent_count)[-sent_count:]\n",
    "            \n",
    "            for i in chosen_idx:\n",
    "                chosen_sent.append(sents[i]) \n",
    "                   \n",
    "        pred_sent, _ = mmr(chosen_sent, sent_count, cluster.get_all_anchor())\n",
    "        predictions.append(' '.join(pred_sent))\n",
    "        \n",
    "    print(\"Start write to txt\")\n",
    "    with open(os.path.join(\"/home/dang/vlsp-final-year/data/result/outer/combination\", \"results.txt\"), \"w\") as f:\n",
    "        for summary in predictions:\n",
    "            summary.replace('_', ' ')\n",
    "            f.write(summary)\n",
    "            f.write('\\n')\n",
    "    print(\"Done write to txt\")\n",
    "                \n",
    "    print(\"Using weight\\n\", weights)\n",
    "    print(\"Sigma: \", sigma)\n",
    "    #print(\"Train result\\n\", train_storage.summary_score())\n",
    "    print(\"Valid result\\n\", valid_storage.summary_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c109cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n",
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:41,  2.22s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.0, 'lexrank': 0.0, 'textrank': 1.0}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.366393  0.143750  0.777778  0.132189\n",
      "1  rouge_1_r  0.518670  0.244681  0.881481  0.129720\n",
      "2  rouge_1_f  0.418849  0.181102  0.767123  0.114617\n",
      "3  rouge_2_p  0.183088  0.004950  0.736842  0.144336\n",
      "4  rouge_2_r  0.261150  0.009174  0.766497  0.166464\n",
      "5  rouge_2_f  0.207887  0.006431  0.725389  0.144542\n",
      "6  rouge_l_p  0.339394  0.118750  0.777778  0.135426\n",
      "7  rouge_l_r  0.478732  0.202128  0.874074  0.135530\n",
      "8  rouge_l_f  0.387353  0.149606  0.767123  0.121121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:36,  2.16s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.0, 'lexrank': 0.3, 'textrank': 0.7}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.369039  0.158996  0.777778  0.117575\n",
      "1  rouge_1_r  0.525461  0.256098  0.865854  0.125274\n",
      "2  rouge_1_f  0.422415  0.233129  0.767123  0.101047\n",
      "3  rouge_2_p  0.183769  0.014493  0.736842  0.136036\n",
      "4  rouge_2_r  0.270325  0.022727  0.724771  0.160386\n",
      "5  rouge_2_f  0.211231  0.017699  0.725389  0.137155\n",
      "6  rouge_l_p  0.342395  0.121339  0.777778  0.119240\n",
      "7  rouge_l_r  0.486721  0.242718  0.865854  0.129056\n",
      "8  rouge_l_f  0.391665  0.177914  0.767123  0.106531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:29,  2.10s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.0, 'lexrank': 0.7, 'textrank': 0.30000000000000004}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.368674  0.164384  0.777778  0.116763\n",
      "1  rouge_1_r  0.524723  0.256098  1.000000  0.130312\n",
      "2  rouge_1_f  0.422194  0.238372  0.767123  0.100162\n",
      "3  rouge_2_p  0.180773  0.018692  0.736842  0.132320\n",
      "4  rouge_2_r  0.267070  0.033898  0.954128  0.169757\n",
      "5  rouge_2_f  0.207599  0.024096  0.725389  0.135704\n",
      "6  rouge_l_p  0.340693  0.139738  0.777778  0.119084\n",
      "7  rouge_l_r  0.484065  0.243902  1.000000  0.136730\n",
      "8  rouge_l_f  0.389793  0.180392  0.767123  0.107263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:30,  2.10s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.0, 'lexrank': 1.0, 'textrank': 0.0}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.372168  0.130769  0.789474  0.121261\n",
      "1  rouge_1_r  0.515155  0.254717  0.841463  0.122068\n",
      "2  rouge_1_f  0.421193  0.184783  0.709220  0.100951\n",
      "3  rouge_2_p  0.179401  0.006024  0.672414  0.136876\n",
      "4  rouge_2_r  0.247517  0.017544  0.724771  0.151253\n",
      "5  rouge_2_f  0.200243  0.008969  0.574713  0.132290\n",
      "6  rouge_l_p  0.343728  0.130769  0.771930  0.120429\n",
      "7  rouge_l_r  0.475218  0.198113  0.817073  0.124304\n",
      "8  rouge_l_f  0.388771  0.174905  0.680851  0.103762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:41,  2.21s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.3, 'lexrank': 0.0, 'textrank': 0.7}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.379158  0.154762  0.774648  0.123898\n",
      "1  rouge_1_r  0.494959  0.268293  0.760563  0.127948\n",
      "2  rouge_1_f  0.419984  0.203922  0.758621  0.109429\n",
      "3  rouge_2_p  0.194048  0.006211  0.755319  0.136478\n",
      "4  rouge_2_r  0.258341  0.008547  0.724490  0.152018\n",
      "5  rouge_2_f  0.215093  0.007194  0.739583  0.137043\n",
      "6  rouge_l_p  0.355173  0.132867  0.774648  0.127829\n",
      "7  rouge_l_r  0.462572  0.219512  0.743243  0.132293\n",
      "8  rouge_l_f  0.393092  0.168889  0.758621  0.116498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:37,  2.18s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.3, 'lexrank': 0.3, 'textrank': 0.39999999999999997}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.375230  0.178344  0.791045  0.109747\n",
      "1  rouge_1_r  0.492525  0.182927  0.841463  0.124020\n",
      "2  rouge_1_f  0.416826  0.188679  0.751773  0.095810\n",
      "3  rouge_2_p  0.178484  0.000000  0.662921  0.116404\n",
      "4  rouge_2_r  0.242727  0.000000  0.710000  0.142872\n",
      "5  rouge_2_f  0.199715  0.000000  0.631016  0.119805\n",
      "6  rouge_l_p  0.350245  0.152866  0.716418  0.110464\n",
      "7  rouge_l_r  0.458786  0.170732  0.817073  0.124023\n",
      "8  rouge_l_f  0.388705  0.176101  0.680851  0.099037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:18,  1.98s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.3, 'lexrank': 0.7, 'textrank': 0.0}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.370004  0.150794  0.921569  0.124889\n",
      "1  rouge_1_r  0.459047  0.244444  0.887324  0.123946\n",
      "2  rouge_1_f  0.400345  0.211111  0.752000  0.104309\n",
      "3  rouge_2_p  0.164845  0.015075  0.836066  0.139282\n",
      "4  rouge_2_r  0.202687  0.022556  0.840000  0.148134\n",
      "5  rouge_2_f  0.175642  0.018072  0.666667  0.133126\n",
      "6  rouge_l_p  0.340317  0.142857  0.882353  0.124187\n",
      "7  rouge_l_r  0.422103  0.208333  0.887324  0.125403\n",
      "8  rouge_l_f  0.368162  0.200000  0.720000  0.107365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:01,  1.82s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.7, 'lexrank': 0.0, 'textrank': 0.30000000000000004}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.357009  0.122222  0.759259  0.109544\n",
      "1  rouge_1_r  0.394462  0.185714  0.766355  0.120648\n",
      "2  rouge_1_f  0.366628  0.152778  0.762791  0.097337\n",
      "3  rouge_2_p  0.146041  0.010695  0.652174  0.123104\n",
      "4  rouge_2_r  0.158874  0.011905  0.650000  0.126806\n",
      "5  rouge_2_f  0.147240  0.012012  0.647687  0.116834\n",
      "6  rouge_l_p  0.329602  0.122222  0.731481  0.110615\n",
      "7  rouge_l_r  0.363996  0.141667  0.738318  0.119706\n",
      "8  rouge_l_f  0.338311  0.152778  0.734884  0.099302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:50,  1.71s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.7, 'lexrank': 0.3, 'textrank': 5.551115123125783e-17}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.366345  0.086022  0.921569  0.121170\n",
      "1  rouge_1_r  0.393814  0.148148  0.887324  0.109515\n",
      "2  rouge_1_f  0.371772  0.108844  0.752000  0.097320\n",
      "3  rouge_2_p  0.146005  0.000000  0.836066  0.128399\n",
      "4  rouge_2_r  0.150195  0.000000  0.840000  0.121920\n",
      "5  rouge_2_f  0.143549  0.000000  0.666667  0.115114\n",
      "6  rouge_l_p  0.334091  0.086022  0.882353  0.119415\n",
      "7  rouge_l_r  0.358433  0.148148  0.887324  0.108589\n",
      "8  rouge_l_f  0.338658  0.108844  0.720000  0.097945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:45,  1.66s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 1.0, 'lexrank': 0.0, 'textrank': 0.0}\n",
      "Sigma:  0.0\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.364704  0.175000  0.921569  0.121974\n",
      "1  rouge_1_r  0.395959  0.185714  0.887324  0.117834\n",
      "2  rouge_1_f  0.371209  0.187793  0.752000  0.101772\n",
      "3  rouge_2_p  0.151430  0.013423  0.836066  0.136172\n",
      "4  rouge_2_r  0.156261  0.011905  0.840000  0.133594\n",
      "5  rouge_2_f  0.148912  0.013029  0.666667  0.125558\n",
      "6  rouge_l_p  0.336862  0.150000  0.882353  0.122280\n",
      "7  rouge_l_r  0.365113  0.164286  0.887324  0.117950\n",
      "8  rouge_l_f  0.342550  0.176245  0.720000  0.104107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:45,  2.25s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.0, 'lexrank': 0.0, 'textrank': 1.0}\n",
      "Sigma:  0.2\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.373014  0.174157  0.777778  0.125044\n",
      "1  rouge_1_r  0.527969  0.300000  0.853659  0.119273\n",
      "2  rouge_1_f  0.427023  0.227941  0.767123  0.104911\n",
      "3  rouge_2_p  0.187049  0.027624  0.736842  0.139520\n",
      "4  rouge_2_r  0.270666  0.045872  0.743119  0.159667\n",
      "5  rouge_2_f  0.214464  0.034483  0.725389  0.140282\n",
      "6  rouge_l_p  0.345871  0.151685  0.777778  0.131635\n",
      "7  rouge_l_r  0.487857  0.241667  0.853659  0.129888\n",
      "8  rouge_l_f  0.395391  0.198529  0.767123  0.116447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:47,  2.28s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.0, 'lexrank': 0.3, 'textrank': 0.7}\n",
      "Sigma:  0.2\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.374363  0.150000  0.777778  0.124951\n",
      "1  rouge_1_r  0.543556  0.300000  0.865854  0.119774\n",
      "2  rouge_1_f  0.432487  0.202817  0.767123  0.105483\n",
      "3  rouge_2_p  0.190118  0.011236  0.736842  0.138955\n",
      "4  rouge_2_r  0.284030  0.028369  0.761468  0.164144\n",
      "5  rouge_2_f  0.220464  0.016097  0.725389  0.141361\n",
      "6  rouge_l_p  0.348337  0.125000  0.777778  0.130496\n",
      "7  rouge_l_r  0.503685  0.241667  0.865854  0.128561\n",
      "8  rouge_l_f  0.401720  0.169014  0.767123  0.115275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:47,  2.27s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.0, 'lexrank': 0.7, 'textrank': 0.30000000000000004}\n",
      "Sigma:  0.2\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.376367  0.168033  0.777778  0.123174\n",
      "1  rouge_1_r  0.547599  0.287129  1.000000  0.129159\n",
      "2  rouge_1_f  0.435368  0.228137  0.767123  0.107077\n",
      "3  rouge_2_p  0.192188  0.026954  0.736842  0.139637\n",
      "4  rouge_2_r  0.291199  0.061644  0.954128  0.174255\n",
      "5  rouge_2_f  0.224029  0.041494  0.725389  0.144185\n",
      "6  rouge_l_p  0.350970  0.143443  0.777778  0.128966\n",
      "7  rouge_l_r  0.508858  0.241667  1.000000  0.138071\n",
      "8  rouge_l_f  0.405372  0.204082  0.767123  0.116822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [03:34,  2.15s/it]\n",
      "WARNING:root:MMR-init: Start create a MMR Summarizer instance\n",
      "WARNING:root:Start create SBERT embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weight\n",
      " {'tfidf': 0.0, 'lexrank': 1.0, 'textrank': 0.0}\n",
      "Sigma:  0.2\n",
      "Valid result\n",
      "         name      mean       min       max       std\n",
      "0  rouge_1_p  0.379527  0.127820  0.789474  0.124259\n",
      "1  rouge_1_r  0.535048  0.234043  0.987805  0.131424\n",
      "2  rouge_1_f  0.433591  0.171206  0.781116  0.107542\n",
      "3  rouge_2_p  0.196816  0.005587  0.672414  0.144968\n",
      "4  rouge_2_r  0.280601  0.016949  0.917431  0.168303\n",
      "5  rouge_2_f  0.223475  0.008475  0.692857  0.142517\n",
      "6  rouge_l_p  0.354291  0.116564  0.771930  0.127747\n",
      "7  rouge_l_r  0.497997  0.202128  0.987805  0.137298\n",
      "8  rouge_l_f  0.404290  0.147860  0.781116  0.114882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /home/dang/vlsp-final-year/external/sentence_transformer/vn_sbert_deploy/bpe/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n",
      "WARNING:root:Create SBERT embedding complete\n",
      "WARNING:root:MMR-init: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on training set\n",
      "Test on valid set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:39,  2.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22964/3710247564.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             }\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mget_rouge_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22964/1653722145.py\u001b[0m in \u001b[0;36mget_rouge_score\u001b[0;34m(weights, sigma)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mchosen_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mpred_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_anchor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSENT_SPLITTED_TOKEN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vlsp-final-year/src/model/mmr_query.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sentences, n_sent, title)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mchosen_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0munchosen_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0membedding_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vlsp-final-year/src/utils/embedding.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vlsp-final-year/external/sentence_transformer/sentence_transformers/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlength_sorted_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mlongest_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mbatch_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vlsp-final-year/external/sentence_transformer/sentence_transformers/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vlsp-final-year/sentence_transformers/models/PhoBERT.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mTokenizes\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaps\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_seq_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vlsp-final-year/sentence_transformers/models/tokenizer/PhoTokenizer.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vlsp-final-year/sentence_transformers/models/tokenizer/PhoTokenizer.py\u001b[0m in \u001b[0;36msegment\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;34m''' Segment words in text and then flat the list '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0msegmented_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdrsegmenter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegmented_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/vncorenlp/vncorenlp.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wseg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'form'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/vncorenlp/vncorenlp.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, text, annotators)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;34m'props'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mannotators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         }\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/handle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m                 )\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnknownProtocol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebuglevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mparse_headers\u001b[0;34m(fp, _class)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0mhstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iso-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsestr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/email/parser.py\u001b[0m in \u001b[0;36mparsestr\u001b[0;34m(self, text, headersonly)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \"\"\"\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadersonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheadersonly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/email/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, fp, headersonly)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mfeedparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/email/feedparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;34m\"\"\"Push more data into the parser.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/email/feedparser.py\u001b[0m in \u001b[0;36m_call_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/email/feedparser.py\u001b[0m in \u001b[0;36m_parsegen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Done with the headers, so parse them and figure out what we're\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# supposed to see in the body of the message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;31m# Headers-only parsing is a backwards compatibility hack, which was\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# necessary in the older parser, which could raise errors.  All\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nckh-nlp/lib/python3.7/email/feedparser.py\u001b[0m in \u001b[0;36m_parse_headers\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mlastheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mlastvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;31m# Check for continuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m' \\t'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sigma in [0.0, 0.2, 0.8, 1.0]:\n",
    "    for i in [0.0, 0.3, 0.7, 1.0]:\n",
    "        for j in [0.0, 0.3, 0.7, 1.0]:\n",
    "            if i + j > 1.0:\n",
    "                continue \n",
    "            k = 1.0 - i - j \n",
    "\n",
    "            weight = {\n",
    "                \"tfidf\": i,\n",
    "                \"lexrank\": j,\n",
    "                \"textrank\": k\n",
    "            }\n",
    "\n",
    "            get_rouge_score(weight, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = {\n",
    "    \"tfidf\": 0.0,\n",
    "    \"lexrank\": 0.8,\n",
    "    \"textrank\": 0.2,\n",
    "    \"sigma\": 0.9\n",
    "}\n",
    "\n",
    "get_rouge_score_and_saved(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2357e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
